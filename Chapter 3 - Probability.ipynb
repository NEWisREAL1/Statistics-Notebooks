{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db10442e-596b-4290-871e-75e4c3968a9f",
   "metadata": {},
   "source": [
    "# Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0577b4c-8be6-4f06-abe1-1c5b9e84bc97",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a81353-2b4f-4310-be2d-37b76df9e9cf",
   "metadata": {},
   "source": [
    "## Sample Spaces and Events\n",
    "\n",
    "An **experiment** is any activity or process whose outcome is subject to uncertainty. It is a procedure that can be infinitely repeated and *has a well-defined set of possible outcomes*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1050a4f4-8655-4cad-aeae-2655598abadc",
   "metadata": {},
   "source": [
    "---\n",
    "### The Sample Space of an Experiment\n",
    "\n",
    "> We called the *set of all possible outcomes* of an experiment the **sample space** of the experiment, denoted by $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b73377-e6f0-4ee7-8eb8-6cd72f8da85e",
   "metadata": {},
   "source": [
    "For examples:\n",
    "\n",
    "- One of the simplest experiment is _tossing a coin_. The possible outcomes of this experiment is _\"the coin comes up heads\"_ and _\"the coin comes up tails\"_. We may write the sample space of tossing a coin as $$S = \\{H,T\\}$$ where $H$ represents _\"heads\"_ and $T$ represents _\"tails\"_.\n",
    "\n",
    "- Consider the experiment of _tossing a six-faced die_. If we are interested in the number that shows on the top face, the sample space is $S=\\{1,2,3,4,5,6\\}$. If we interested only in whether the number on the top face is odd or even, then the sample space is $S=\\{\\text{odd},\\text{even}\\}$.\n",
    "\n",
    "- Consider an experiment consists of _examining a single fuse to see whether it is defective_. The sample space for this experiment can be abbreviated as $S=\\{N,D\\}$ where $N$ represents _\"not defective\"_ and $D$ represents _\"defective\"_. If we instead _examine three fuses in sequence_ and note the result of each examination, then an outcome for the entire experiment is any sequence of $N$'s and $D$'s of length 3, so $$S=\\{NNN, NND, NDN, DNN, NDD, DND, DDN, DDD\\}.$$\n",
    "\n",
    "- An experiment consists of flipping a coin and then flipping it a second time if a head occurs on the first flip. If a tail occurs on the first flip, then a die is tossed once. The sample space of this experiment if we interested in the side of the coin that comes up and the top face of the die is $$S=\\{HH, HT, T1, T2, T3, T4, T5, T6\\}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9b197-916d-40e0-ae30-c184bd2c72c1",
   "metadata": {},
   "source": [
    "We called each outcome in a sample space a **sample point**. For example, when tossing a coin, the sample space is $S=\\{H,T\\}$ so the outcomes $H$ and $T$ are samples points. \n",
    "\n",
    "We will commonly interested in size of sample space—*the number of sample points in a sample space*, abbreviated $n(S)$. From the examples shown above, we can simply just count the sample point.\n",
    "\n",
    "- $S=\\set{H,T} \\longrightarrow n(S)=2.$\n",
    "- $S=\\set{1,2,3,4,5,6} \\longrightarrow n(S)=6.$\n",
    "- $S$ being a sample space of examining three fuses in sequence $\\longrightarrow n(S)=8.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9906eff6-17dd-469a-b399-2e477040df3a",
   "metadata": {},
   "source": [
    "---\n",
    "### Events\n",
    "\n",
    "> An **event** is *any collection of outcomes contained in the sample space (any subset of sample space)*. An event is **simple** if it consists of exactly one outcome and **compound** if it consists of more than one outcome.\n",
    "> $$\\text{Event} \\subseteq S.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f4c51-a497-4c30-9ec6-b4d2ef9bd380",
   "metadata": {},
   "source": [
    "When an experiment is performed, a particular event $E$ is said to occur if the resulting outcome is contained in $E$. In general, exactly one simple event will occur, but many compound events will occur simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19711d44-4b26-4b5f-9948-73fad3d185bc",
   "metadata": {},
   "source": [
    "For example, consider the experiment of tossing three coins in sequence. So the sample space of this experiment is $S=\\set{HHH, HHT, HTH, THH, HTT, THT, TTH, TTT}$. Thus there are eight simple events, each consists of only a single sample point of the sample space, among which are $E_1=\\set{HHH}$ and $E_2=\\set{HTT}$. Some compound events include:\n",
    "\n",
    "- $A = \\set{HHT, HTH, THH} = $ the event where exactly one coin comes up tails.\n",
    "- $B = \\set{HHH, TTT} = $ the event that all three coins come up the same side.\n",
    "- $C = \\set{HHT, HTH, THH, HTT, THT, TTH, TTT} = $ the event that at least one coin comes up heads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcd62d5-f68c-45f3-a8d0-d8c4932c8bfd",
   "metadata": {},
   "source": [
    "---\n",
    "### Some Relations from Set Theory\n",
    "\n",
    "**An event is just a set**, so any operations that can be done on sets can also be done on events to create another event:\n",
    "\n",
    "1. The **complement** of an event $E$, denoted by $E'$ or $\\bar{E}$ or $\\neg E$, is the event that *$E$ does not occur*.\n",
    "2. The **union** of two events $A$ and $B$, denoted by $A \\cup B$ and read *\"A or B\"*, is the event where *either $A$ or $B$ or both occur*.\n",
    "3. The **intersection** of two events $A$ and $B$, denoted by $A \\cap B$ and read *\"A and B\"*, is the event where *both $A$ and $B$ occur*.\n",
    "4. If $A \\cap B = \\emptyset$ where $\\emptyset$ is the *null event* (the event consisting of no outcomes), then $A$ and $B$ are said to be **mutually exclusive** or **disjoint** events. That is they can not occur simultaneously.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> \n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/73/Venn10.svg/225px-Venn10.svg.png\" alt=\"complement\" style=\"height: 150px;\"/>\n",
    "        </td>\n",
    "        <td> \n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Venn0111.svg/330px-Venn0111.svg.png\" alt=\"union\" style=\"height: 150px;\"/> \n",
    "        </td>\n",
    "        <td> \n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Venn0001.svg/330px-Venn0001.svg.png\" alt=\"intersection\" style=\"height: 150px;\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: center;\">Complement</td>\n",
    "        <td style=\"text-align: center;\">Union</td>\n",
    "        <td style=\"text-align: center;\">Intersection</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c060c-640b-4d7d-97e2-d2efc01bf8ad",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fbc0b-53f4-427e-afc9-e5ba58f03ef1",
   "metadata": {},
   "source": [
    "## What is Probability?\n",
    "\n",
    "> The term **probability** refers to the study of *randomness and uncertainty*. In any\n",
    "situation in which one of a number of possible outcomes may occur, the discipline of probability provides methods for quantifying the chances, or likelihoods, associated with the various outcomes. — Jay L. Devore, 2012\n",
    "\n",
    "Let's begin the discussion by looking at the data example. *\"According to the National Center for Health Statistics, in 2015, there were about 4 million babies born in the U.S., and 48.8% of the newborns were girls.\"* So, based on the statistics, if we look at a baby that's born someday in 2015 in the U.S., then the chance of that baby being a girl is 48.8% (and the chance of being a boy is 51.2% accordingly). Notionally, we write:\n",
    "\n",
    "$$\n",
    "P(\\text{event}) = \\text{the probability that the \"event\" will happen}.\n",
    "$$\n",
    "\n",
    "In this case, we write: $P(\\text{``newborn is a girl\"}) = 48.8\\%$.\n",
    "\n",
    "Conventionally, probabilities are always between 0 and 1, we can convert them into percentage if we want (e.g. 0.5 = 50%, 0.1 = 10%, 1.0 = 100%). We commonly used symbols to represent an event. For example, we might defined $A$ to be the event that a newborn in U.S. in 2015 is a girl, so we write\n",
    "\n",
    "$$\n",
    "P(\\text{``newborn is a girl\"}) \\;=\\; P(A) \\;=\\; 0.488\n",
    "$$\n",
    "\n",
    "The example above shows that the **probability of an event** is defined as the ***proportion of time* the event occurs** in many repetitions. This is the standard definition of probability and it requires that we look at a chance experiment that can be repeated many times.\n",
    "\n",
    "However, this definition can make it difficult to interpret for single-run events. Sometimes people use a different definition of probability For example, \"The chance that my dad will call me today is 60%.\" Clearly this statement cannot be interpreted as a long-run frequency because \"today\" happen only once. In this case it is a subjective feeling of the chance that the event will happen. This is called a **subjective probability** which is not based on experiments and different subjects may assign different subjective probabilities to the same event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41212674-3428-4ca6-9b4d-902e95c97930",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a473b55-2540-4a0f-a085-97755299916d",
   "metadata": {},
   "source": [
    "## The Basic Rules of Probability\n",
    "\n",
    "The rules of probability we will be discuss in this section comes from the following set of axioms:\n",
    "\n",
    "1. For any event $A$, $P(A) \\ge 0$.\n",
    "2. $P(S) = 1$.\n",
    "3. If $A_1, A_2, A_3, \\ldots$ is an infinite collection of disjoint events, then $$P(A_1 \\cup A_2 \\cup \\cdots) = \\sum_{i=1}^n P(A_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6ed5ac-52de-4633-8b7f-2aa36ff39b55",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: 14pt;\">Complement Rule</h3>\n",
    "\n",
    "The complement rule states that the sum of the probability that an event occurring and the probability that the event not occurring must equal $1$. Namely\n",
    "\n",
    "$$\n",
    "P(A \\text{ does not occur}) = 1 - P(A).\n",
    "$$\n",
    "\n",
    "We called the event that $A$ does not occur the **complement** of $A$, denoted $A'$ or $\\bar{A}$. Using this notation, we can write:\n",
    "\n",
    "$$\n",
    "P(A') = 1 - P(A).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1bf850-bccf-40ca-b3dc-0a83d078bd0c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: 14pt;\">Equally Likely Outcomes</h3>\n",
    "\n",
    "If an experiment have $n$ different possible outcomes, wriiten as events $E_1, E_2, \\ldots, E_n$ and all outcomes are equally likely to happen. Then\n",
    "\n",
    "$$\n",
    "P(E_i) = \\frac{1}{n}, \\;\\; \\text{ for all } i = 1, 2, \\ldots, n.\n",
    "$$\n",
    "\n",
    "For example, consider rolling a six-sided dice, each of its six faces is equally likely to come up, so the probability that each face will come up is $\\frac{1}{6}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf763789-379a-4d0c-bb61-e902f8f9695c",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: 14pt;\">Addition Rule</h3>\n",
    "\n",
    "If $A$ and $B$ are mutually exclusive, then the probability of $A$ or $B$ occurring is equal to the sum of there probability:\n",
    "\n",
    "$$\n",
    "P(A \\text{ or } B) \\;=\\; P(A \\cup B) \\;=\\; P(A) + P(B).\n",
    "$$\n",
    "\n",
    "This rule just come directly from the axiom number 3 mentioned previously. For two events $A$ and $B$ that are not mutually exclusive, we can used the principle of inclusion-exclusion from set theory and calculate:\n",
    "\n",
    "$$\n",
    "P(A \\cup B) \\;=\\; P(A) + P(B) - P(A \\cap B).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5997d0f1-56c7-4bff-b994-c0111b4320ad",
   "metadata": {},
   "source": [
    "<h3 style=\"color: green; font-size: 14pt;\">Independent Events and Multiplication Rule</h3>\n",
    "\n",
    "The events $A$ and $B$ are called **independent** if **knowing that one occurs doesn't change the probability that the other occurs**. For example, in the same experiment as described above, the events $A$ and $B$ are _not_ independent because if $A$ occurs, we know that $B$ cannot occur. This means that knowing one event occurs affects the probability of the other. On the other hand, $A$ and $C$ are independent since the result of the first roll does not affect the result of the next roll. \n",
    "\n",
    "If $A$ and $B$ are independent, then the probability that both $A$ and $B$ occurring is equal to the product of there probability:\n",
    "\n",
    "$$\n",
    "P(A \\text{ and } B) \\;=\\; P(A \\cap B) \\;=\\; P(A)P(B).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c30793-8621-4183-86f1-555dbc6cd4bd",
   "metadata": {},
   "source": [
    "---\n",
    "<h3 style=\"color: green; font-size: 14pt;\">An Example of Applying Probability Rules</h3>\n",
    "\n",
    "Suppose do an experiment of rolling a die three times and ask *\"What is the probability of rolling at least 1 six?\"*.\n",
    "\n",
    "We can apply the method of **total enumeration** to solve this problem. The idea is to split the event we interested in into multiple possibilities. In this case we could write *\"at least one six\"* as *\"six on the first roll\" **or** \"six on the second roll\" **or** \"six on the third roll\"*. For convenient sake, we define $s_1$, $s_2$, and $s_3$ to be the event *\"six on the first roll\"*, *\"six on the scond roll\"*, and *\"six on the third roll\"* respectively. So we can write:\n",
    "\n",
    "$$\n",
    "P(\\text{``at least one six\"}) = P(s_1 \\cup s_2 \\cup s_3).\n",
    "$$\n",
    "\n",
    "Seeing that there are \"or (union)\" between the events, we might want to apply the addition rule, but the event $s_1$, $s_2$, and $s_3$ are not mutually exclusive since they can happen at the same time with the others (they can happen in the same run of the experiment). Therefore we cannot aapply the addition rule.\n",
    "\n",
    "Let's consider using the complement rule, so we have:\n",
    "\n",
    "$$\n",
    "P(\\text{``at least one six\"}) = 1 - P(\\text{``no six in three roll\"}).\n",
    "$$\n",
    "\n",
    "Now, we could write *\"no six in three roll\"* as *\"no six on the first roll\" **and** \"no six on the second roll\" **and** \"no six on the third roll\"*. That is:\n",
    "\n",
    "$$\n",
    "P(\\text{``at least one six\"}) = 1 - P(s_1' \\cap s_2' \\cap s_3').\n",
    "$$\n",
    "\n",
    "The events $s_1'$, $s_2'$, and $s_3'$ are independent since the occurance of one does not affect the others. So we can apply the multiplication rule to this expression:\n",
    "\n",
    "$$\n",
    "P(\\text{``at least one six\"}) = 1 - P(s_1')P(s_2')P(s_3').\n",
    "$$\n",
    "\n",
    "We know that each face of the dice is equally likely to come up. Thus, by the rule of equally likely outcomes, the probability that we will roll a six is $1/6$, which is the value of $s_1$, $s_2$, and $s_3$. And by the complement rule, we get $s_1' = s_2' = s_3' = 1 - 1/6 = 5/6$. Finally, we can substitude these values into the equation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\text{``at least one six\"}) &= 1 - P(s_1')P(s_2')P(s_3') \\\\\n",
    "&= 1 - (\\frac{5}{6} \\times \\frac{5}{6} \\times \\frac{5}{6}) \\\\\n",
    "&= 1 - \\frac{125}{216} \\\\\n",
    "&\\approx 0.4213  \\\\\n",
    "&= 42.13\\%\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And that's the final answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c9dd9-df40-473a-8332-54f7754c3a23",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699b659-512e-46a1-bcbd-012c5bcccef6",
   "metadata": {},
   "source": [
    "## Conditional Probability\n",
    "\n",
    "Conditional probability is a measure of the probability of an event occurring, **given that another event is already known to have occurred**. We wirte \"the conditional probability of A given B\" as $P(A|B)$.\n",
    "\n",
    "For example, suppose we do an analysis on spam emails and found that spam emails have 8% chance to contain the word *\"money\"* which is higer that the chance of the same word occurring in ham emails (emails that are not spams) of 1%. We may write:\n",
    "\n",
    "$$\n",
    "P(\\text{``money\"} \\;|\\; \\text{spam}) = 8\\% \\quad\\text{ and }\\quad P(\\text{``money\"} \\;|\\; \\text{ham}) = 1\\%.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921f9f8-3f6e-4032-bc9a-5cb2020a0074",
   "metadata": {},
   "source": [
    "The conditional probability $P(A|B)$ can be understood as the fraction of probability of $B$ which intersects with $A$:\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}.\n",
    "$$\n",
    "\n",
    "The formula often rearranged as:\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(A)P(B|A) = P(B)P(A|B).\n",
    "$$\n",
    "\n",
    "This formula is called the **general multiplication rule**, which extents the multiplication rule for two events that are not independent. Notice that in the special case where $A$ and $B$ are independent, knowing that $B$ happened does not affect the probability of $A$, so $P(A|B) = P(A)$ which implies $P(A \\cap B) = P(B)P(A)$ which is the multiplication rule mentioned earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159093ad-26d1-4715-bc76-75fd5fccf006",
   "metadata": {},
   "source": [
    "---\n",
    "<h3 style=\"color: green; font-size: 14pt;\">Calculation Example</h3>\n",
    "\n",
    "Given the information:\n",
    "\n",
    "- 20% or all emails are spams.\n",
    "- There are 8% chance that a spam email contain the word \"money\".\n",
    "- There are 1% chance that a spam email contain the word \"money\".\n",
    "\n",
    "We ask _\"What is the probability that the word 'money' appears in an email?\"_.\n",
    "\n",
    "From the data, we write:\n",
    "\n",
    "- $P(\\text{spam}) = 0.2\\%$.\n",
    "- $P(\\text{``money\"}\\;|\\;\\text{spam}) = 0.08$.\n",
    "- $P(\\text{``money\"}\\;|\\;\\text{ham}) = 0.01$.\n",
    "\n",
    "And we can write the event *\"the word 'money' appears in an email\"* as *\"the word 'money' appears in spam\"* or *\"the word 'money' appears in ham\"*. Since those two events are mutually exclusive, we can apply the addition rule:\n",
    "\n",
    "$$\n",
    "P(\\text{``money\"}) = P(\\text{``money\" and spam}) + P(\\text{``money\" and ham}).\n",
    "$$\n",
    "\n",
    "Now apply the general multiplication rule, so we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\text{``money\"}) &= P(\\text{``money\"}\\;|\\;\\text{spam})P(\\text{spam}) + P(\\text{``money\"}\\;|\\;\\text{ham})P(\\text{ham}) \\\\\n",
    "&= (0.08)(0.2) + (0.01)(1 - 0.2) \\\\\n",
    "&= 0.024 = 2.4\\%.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Therefore, the probability that the word 'money' appears in an email is 2.4%.\n",
    "\n",
    "This kind of calculation can be applied to build a *spam filter*. But went we do build one, the question we need to solve is *\"what is the probability that an email is a spam, given that it contain a particular word\"*. For instance, we need to find\n",
    "$$\n",
    "P(\\text{email is a spam} \\;|\\; \\text{email contain the word ``money\"})\n",
    "$$\n",
    "\n",
    "But by observation (e.g. scanning tons of emails), we can only get $P(\\text{email contain the word ``money\"} \\;|\\; \\text{email is a spam})$. Which is the reverse of what we want. We will discuss the method used to reverse the conditional probability in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68182144-18e4-437d-b6f1-db5803c3816e",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ae14c-1046-498d-995a-96afd053cbb1",
   "metadata": {},
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "Suppose that we know the value of $P(A|B)$ but we want to calculate $P(B|A)$, then what can we do? Let's start by rearranging the conditional probability formula:\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(B \\cap A)}{P(A)}.\n",
    "$$\n",
    "\n",
    "Since the order of \"and\" (intersect) doesn't matter, we can write the general multiplication rule as:\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(B)P(A|B) = P(A)P(B|A) = P(B \\cap A).\n",
    "$$\n",
    "\n",
    "We can then plug in this into the conditional probability formula:\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(B \\cap A)}{P(A)} = \\frac{P(A \\cap B)}{P(A)} = \\frac{P(B)P(A|B)}{P(A)}\n",
    "$$\n",
    "\n",
    "And that is what we wanted: we derived the formula that express $P(B|A)$ in terms of $P(A|B)$. This formula is called **Bayes' theorem**. \n",
    "\n",
    "In real-applications (most of the time), the value of $P(A)$ is not directly given. However, we can calculate it as shown in the previous section. Therefore, Bayes' theorem is often written explicitly with $P(A)$ expressed as\n",
    "\n",
    "$$\n",
    "P(B|A) \\;=\\; \\frac{P(B)P(A|B)}{P(A)} \\;=\\; \\frac{ P(B)P(A|B) }{ P(B)P(A|B) + P(B')P(A|B') }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a721196-d6cf-47f8-a17c-cd847fd20d6d",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38bc5b6-3b20-485d-b98c-36d51c6dc903",
   "metadata": {},
   "source": [
    "## Bayesian Analysis & Examples Case Studies\n",
    "\n",
    "As we saw in the last section. Bayesian probability interprets probabilities based on a *degree of belief* in an event since this interpretation is defined by conditional probability, which determines the probability of an event given the probability (belief) of another event. \n",
    "\n",
    "In Bayesian analysis, we begin with some **prior** knowledge (or prior belief) about the event. Then, as we examine new data, we update the prior probability using Bayes' theorem to arrive at the **posterior** knowledge (or posterior belief).\n",
    "\n",
    "A great example would be a spam filter. We might have a dataset of emails in which 20% of the data are spam emails, so the prior probability that an email is a spam is 20%. After that, we examime the emails for certain keywords, calculate the probabilities that the keywords appear in spam or non-spam emails, and use these probabilities to update the prior probability to get a better estimate of whether a new email is spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4376cf6-a857-424f-af9a-2966ab6f7811",
   "metadata": {},
   "source": [
    "---\n",
    "<h3 style=\"color: green; font-size: 14pt;\">Example : False Positives</h3>\n",
    "\n",
    "Suppose that 1% of the population has a certain disease. If an infected person is tested, then there is a 95% chance that the test is positive. If the person is not infected, then there is a 2% chance that the test gives an erroneous positive result (*'false positive'*).\n",
    "\n",
    "To determine whether the test is effective, we ask: \"What is the probability that a person who tests positive, what are the chances that he/she actually has the disease?\"\n",
    "\n",
    "Let $D$ be the event that a person has the disease and $p$ be the event that a person tests positive. Here is the data we have:\n",
    "\n",
    "- $P(D) = 0.01$,\n",
    "- $P(p|D) = 0.95$,\n",
    "- $P(p|D') = 0.02$.\n",
    "\n",
    "And want we want to know is $P(D|p)$. We can see that the probability we want is the reverse of want we know, so Bayes' theorem can be apply to solve the problem:\n",
    "\n",
    "$$\n",
    "P(D|p) = \\frac{P(D)P(p|D)}{P(p)}.\n",
    "$$\n",
    "\n",
    "Since $P(p)$ is not directly known, we use the expanded form of Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(D|p) &= \\frac{ P(D)P(p|D) }{ P(D)P(p|D) + P(D')P(p|D') } \\\\\n",
    "&= \\frac{ (0.01)(0.95) }{ (0.01)(0.95) + (1 - 0.01)(0.02) } \\\\\n",
    "&= \\frac{0.0095}{0.0095 + 0.0198} \\\\ \\\\\n",
    "&\\approx 0.3242 = 32.45\\%\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "We can see that the performance of the test is relatively low, despite a very small false positive rate. This is because the proportion of the population with the disease is very small compared to the proportion without the disease. As a result, even a small error rate, when applied to the much larger group of non-infected individuals, can lead to a significant number of false positives.\n",
    "\n",
    "The technical term **\"false positive\"** refers to an error in which a test result incorrectly indicates the *presence* of a condition (e.g. a disease when the disease is not present), while a **false negative** is the opposite error, where the test result incorrectly indicates the *absence* of a condition when it is actually present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49f6de-144d-43a0-96ee-6a892e9abdfd",
   "metadata": {},
   "source": [
    "---\n",
    "<h3 style=\"color: green; font-size: 14pt;\">Case Study: Warner's Randomized Response Model</h3>\n",
    "\n",
    "Suppose we want to know *\"What percentage of students have cheated during the exam in a college?\"* This question can be tricky to answer since students may not (or may) answer truthfully if we do a survey.\n",
    "\n",
    "A research method called **randomized response** proposed by S. L. Warner allows respondents to respond to sensitive issues while maintaining confidentiality using randomization. Chance decides, **unknown to the interviewer**, whether the question is to be answered truthfully, or \"yes\", regardless of the truth.\n",
    "\n",
    "For example, we may do a survey that first requires the students to toss a coin twice, then instructs them to answer question 1 if they gets 'tail' on the first toss and answer to question 2 if they gets 'head' on the first toss. And we may set the two questions as\n",
    "\n",
    "- Question 1: Have you ever cheated on an exam in college?\n",
    "- Question 2: Did you get tail on the second toss?\n",
    "\n",
    "We do not know whether a \"yes\" answer is due to the student cheating or to getting tails on the second toss. This should put the student at ease to answer truthfully.\n",
    "\n",
    "While not knowing what an individual answer means. We can estimate the proportion of cheaters using all the answer collectively. First we splits the event that a student answer \"yes\" into two parts:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\text{``yes\"}) &= P(\\text{``yes\"} \\cap \\text{Q1}) + P(\\text{``yes\"} \\cap \\text{Q2}) \\\\\n",
    "&= P(\\text{Q1})P(\\text{``yes\"} \\;|\\; \\text{Q1}) + P(\\text{Q2})P(\\text{``yes\"} \\;|\\; \\text{Q2}).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "So the answer we want to know would be:\n",
    "\n",
    "$$\n",
    "P(\\text{``yes\"} \\;|\\; \\text{Q1}) = \\frac{ P(\\text{``yes\"}) - P(\\text{Q2})P(\\text{``yes\"} \\;|\\; \\text{Q2}) }{ P(\\text{Q1}) }.\n",
    "$$\n",
    "\n",
    "All the terms can be determine:\n",
    "\n",
    "- $P(\\text{Q1})$ and $P(\\text{Q2})$: The chance that the student is answer to question 1 or 2, which is the chance that the student gets \"tail\" or \"head\" on the first toss. That is 50%.\n",
    "- $P(\\text{``yes\"} \\;|\\; \\text{Q2})$: The chance that the student answer \"yes\" to question 2, which is equal to the chance that the student gets \"tail\" on the second toss. Which is also 50%.\n",
    "- $P(\\text{``yes\"})$: The proportion of students answered \"yes\", which can be determined from the survey results.\n",
    "\n",
    "Suppose that 27 students answered \"yes\" and 30 students answered \"no\". So we estimate\n",
    "\n",
    "$$\n",
    "P(\\text{``yes\"} \\;|\\; \\text{Q1}) = \\frac{(27/57) - (0.5)(0.5)}{0.5} = 0.4473 = 44.73\\%.\n",
    "$$\n",
    "\n",
    "And that is the estimation of fraction of cheaters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fac167-6108-4039-9979-802b1af7b86e",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
